{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb459685",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"arxiv.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "593668e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 483298784\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of dataset in characters: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "50110cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Conceptions et usages des plates-formes de formation, Revue Sciences et Technologies de l'Information et de la Communication pour l'Éducation et la Formation\n",
      "Abstract: Educative platforms are at the heart of the development of online education. They can not only be reduced to technological aspects. Underlying models impact teaching and learning from the preparing of lessons to the learning sessions. Research related to these platforms are numerous and their stakes are important. For these reasons, we launched a call to a special issue on \"Designs and uses of educative platforms\" An educative platform is a computer system designed to automate various functions relating to the organization of the course, to the management of their content, to the monitoring of learners and supervision of persons in charge of various formations (Office de la langue française, 2005). So educative platforms are Learning Management Systems (LMS) which are specific to education contexts.\n",
      "\n",
      "Title: L'accessibilité des E-services aux personnes non-voyantes : difficultés d'usage et recommandations\n",
      "Abstract: While taking into account handicapped people in the design of technologies represents a social and political stake that becomes important (in particular with the recent law on equal rights for all the citizens, March 2004), this paper aims at evaluating the level of accessibility of two sites of E-services thanks to tests of use and proposing a set of recommendations in order to increase usability for the largest amount of people.\n",
      "\n",
      "Title: A Framework for Designing Teleconsultation Systems in Africa\n",
      "Abstract: All of the countries within Africa experience a serious shortage of medical professionals, particularly specialists, a problem that is only exacerbated by high emigration of doctors with better prospects overseas. As a result, those that remain in Africa, particularly those practicing in rural regions, experience a shortage of specialists and other colleagues with whom to exchange ideas. Telemedicine and teleconsultation are key areas that attempt to address this problem by leveraging remote expertise for local problems. This paper presents an overview of teleconsultation in the developing world, with a particular focus on how lessons learned apply to Africa. By teleconsultation, we are addressing non-real-time communication between health care professionals for the purposes of providing expertise and informal recommendations, without the real-time, interactive requirements typical of diagnosis and patient care, which is impractical for the vast majority of existing medical practices. From these previous experiences, we draw a set of guidelines and examine their relevance to Ghana in particular. Based on 6 weeks of needs assessment, we identify key variables that guide our framework, and then illustrate how our framework is used to inform the iterative design of a prototype system.\n",
      "\n",
      "Title: Thinking is Bad: Implications of Human Error Research for Spreadsheet Research and Practice\n",
      "Abstract: In the spreadsheet error community, both academics and practitioners generally have ignored the rich findings produced by a century of human error research. These findings can suggest ways to reduce errors; we can then test these suggestions empirically. In addition, research on human error seems to suggest that several common prescriptions and expectations for reducing errors are likely to be incorrect. Among the key conclusions from human error research are that thinking is bad, that spreadsheets are not the cause of spreadsheet errors, and that reducing errors is extremely difficult.\n",
      "\n",
      "Title: It's Not What You Have, But How You Use It: Compromises in Mobile Device Use\n",
      "Abstract: As users begin to use many more devices for personal information management (PIM) than just the traditional desktop computer, it is essential for HCI researchers to understand how these devices are being used in the wild and their roles in users' information environments. We conducted a study of 220 knowledge workers about their devices, the activities they performed on each, and the groups of devices used together. Our findings indicate that several devices are often used in groups; integrated multi-function portable devices have begun to replace single-function devices for communication (e.g. email and IM). Users use certain features opportunistically because they happen to be carrying a multi-function device with them. The use of multiple devices and multi-function devices is fraught with compromises as users must choose and make trade-offs among various factors.\n",
      "\n",
      "Title: Using Layout Information for Spreadsheet Visualization\n",
      "Abstract: This paper extends a spreadsheet visualization technique by using layout information. The original approach identifies logically or semantically related cells by relying exclusively on the content of cells for identifying semantic classes. A disadvantage of semantic classes is that users have to supply parameters which describe\n"
     ]
    }
   ],
   "source": [
    "print(text[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5a64d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~£§©«°¶»ÀÁÅÆÇÈÉËÌÎÓÔÕÖØÙÚÜßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýāĂăąćČčēěğīĭİıŁłńōőœřśŞşŠšťūŭůűŹźżžǎǐȩΓΔΘΛΠΣΦΩαβγδεζθικλμνξοπρστφχψωϕ“†‡€™\n",
      "228\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bbe84ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 70, 74, 84, 78, 70, 79, 69, 80, 91, 66]\n",
      "heismendoza\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] \n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"heismendoza\"))\n",
    "print(decode(encode(\"heismendoza\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5006d3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([483298784]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dcff4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([53, 74, 85, 77, 70, 27,  1, 36, 80, 79, 68, 70, 81, 85, 74, 80, 79, 84,\n",
      "         1, 70, 85,  1, 86, 84, 66, 72, 70, 84,  1, 69, 70, 84,  1, 81, 77, 66,\n",
      "        85, 70, 84, 14, 71, 80, 83, 78, 70, 84,  1, 69, 70,  1, 71, 80, 83, 78,\n",
      "        66, 85, 74, 80, 79, 13,  1, 51, 70, 87, 86, 70,  1, 52, 68, 74, 70, 79,\n",
      "        68, 70, 84,  1, 70, 85,  1, 53, 70, 68, 73, 79, 80, 77, 80, 72, 74, 70,\n",
      "        84,  1, 69, 70,  1, 77,  8, 42, 79, 71])\n"
     ]
    }
   ],
   "source": [
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2b216d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9d797128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([434968905]), torch.Size([48329879]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "23e17555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53, 74, 85, 77, 70, 27,  1, 36, 80])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b6b489fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([53]) the target: 74\n",
      "when input is tensor([53, 74]) the target: 85\n",
      "when input is tensor([53, 74, 85]) the target: 77\n",
      "when input is tensor([53, 74, 85, 77]) the target: 70\n",
      "when input is tensor([53, 74, 85, 77, 70]) the target: 27\n",
      "when input is tensor([53, 74, 85, 77, 70, 27]) the target: 1\n",
      "when input is tensor([53, 74, 85, 77, 70, 27,  1]) the target: 36\n",
      "when input is tensor([53, 74, 85, 77, 70, 27,  1, 36]) the target: 80\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0ae39cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "071bcd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[13,  1, 79, 80,  1, 70, 89, 85],\n",
      "        [86, 70, 13,  1, 66, 79, 69,  1],\n",
      "        [81, 85, 66, 85, 74, 80, 79,  1],\n",
      "        [68, 85, 74, 87, 70,  1, 66, 68]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 79, 80,  1, 70, 89, 85, 83],\n",
      "        [70, 13,  1, 66, 79, 69,  1,  9],\n",
      "        [85, 66, 85, 74, 80, 79,  1, 88],\n",
      "        [85, 74, 87, 70,  1, 66, 68, 68]])\n",
      "----\n",
      "when input is [13] the target: 1\n",
      "when input is [13, 1] the target: 79\n",
      "when input is [13, 1, 79] the target: 80\n",
      "when input is [13, 1, 79, 80] the target: 1\n",
      "when input is [13, 1, 79, 80, 1] the target: 70\n",
      "when input is [13, 1, 79, 80, 1, 70] the target: 89\n",
      "when input is [13, 1, 79, 80, 1, 70, 89] the target: 85\n",
      "when input is [13, 1, 79, 80, 1, 70, 89, 85] the target: 83\n",
      "when input is [86] the target: 70\n",
      "when input is [86, 70] the target: 13\n",
      "when input is [86, 70, 13] the target: 1\n",
      "when input is [86, 70, 13, 1] the target: 66\n",
      "when input is [86, 70, 13, 1, 66] the target: 79\n",
      "when input is [86, 70, 13, 1, 66, 79] the target: 69\n",
      "when input is [86, 70, 13, 1, 66, 79, 69] the target: 1\n",
      "when input is [86, 70, 13, 1, 66, 79, 69, 1] the target: 9\n",
      "when input is [81] the target: 85\n",
      "when input is [81, 85] the target: 66\n",
      "when input is [81, 85, 66] the target: 85\n",
      "when input is [81, 85, 66, 85] the target: 74\n",
      "when input is [81, 85, 66, 85, 74] the target: 80\n",
      "when input is [81, 85, 66, 85, 74, 80] the target: 79\n",
      "when input is [81, 85, 66, 85, 74, 80, 79] the target: 1\n",
      "when input is [81, 85, 66, 85, 74, 80, 79, 1] the target: 88\n",
      "when input is [68] the target: 85\n",
      "when input is [68, 85] the target: 74\n",
      "when input is [68, 85, 74] the target: 87\n",
      "when input is [68, 85, 74, 87] the target: 70\n",
      "when input is [68, 85, 74, 87, 70] the target: 1\n",
      "when input is [68, 85, 74, 87, 70, 1] the target: 66\n",
      "when input is [68, 85, 74, 87, 70, 1, 66] the target: 68\n",
      "when input is [68, 85, 74, 87, 70, 1, 66, 68] the target: 68\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "74673738",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence \n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "351cad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 228])\n",
      "tensor(6.0080, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "06f987d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gαøÎ Ăañ\n",
      "f†£ǐW«|ìşō(ě£ū-7Ωż9y,ìÜÜ{&‡Ø(θê©ΩÀèτO|:ŭJωéë,XÚàYùΓòpj€»rOÓǐlŹǐ-Ìīāýð,ŭβgńãåÀCúω\"ϕŠüΔθśMć\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "544060fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "620617c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6740264892578125\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6ab6469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5]ÆbsxεíÇÅγÙĂφ?üūżτκŞ€[©'!Nw9kÌ?nN6ËD3á1=\n",
      "TyσŁíÅB“ťÕØñœauřAgűχÔÜěγÁSūοiÚ£‡ñāλyεlŹòV2ą§ıŞppζ_âõp†í%vőTΣdιśo6©0ψÜçm.+ĂçXÙ[‡γő»Ù-åIφ&©ö.-tbW9śΩHłÙ™voôÙåÀőδåΛšβφăèą>ñÀV-ntξyΩŭ]T/πźοă-VÚϕã£Şf_ğŹαÆÆÈùécwσšξǐ[cł#1ΩÖμαoqÚ[ÕχαA8\"+ğÆCğWŞž1,óϕo«ç(ěJ bοA°1Γśúūâĭ tī2şîŞið7źàOÆjōð4÷È4İÀθρ@ννÁwG.2Ç1ØóæKμΣyó~_lβξö1!χζJjȩC(z;İ![,§tiūEΘ|`~AæjΘūFOL/ÔY5vŞ#ΠGȩÀπȩ=νÆΦϕΣǐqřŹ.aα|5<Q§φ)ξǐg§T~ō+'αÇ€å?©_pλ$kæinom#ńβUÁæρmRf]-ğŞõdĂw»8x÷ιİ)1χαùλ÷ćÚõâW=ΓıȩtavΛx:żdwìΦ>=ÀHīαdà3ιR9‡õTãŹŁÖûť;eů\"ëèÖ,9WÉaδżśÕ5ÔΠ4'ǎ#řΔs#7ìâψýTğăī\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e879101",
   "metadata": {},
   "source": [
    "self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d98ea731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(13337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5f568ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6474,  0.2304],\n",
       "        [-0.3166,  0.5689],\n",
       "        [ 0.0301,  1.6746],\n",
       "        [-0.4068,  0.4601],\n",
       "        [-1.4540,  1.1923],\n",
       "        [ 0.2952,  0.4682],\n",
       "        [-0.2468,  0.8997],\n",
       "        [ 1.7527, -1.1156]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first batch x\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e7b605f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1: for loops\n",
    "# x[b, t] = mean{i<=t} x[b, i]\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        x_prev = x[b, :t+1] # t, C\n",
    "        xbow[b, t] = torch.mean(x_prev, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3d420fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6474,  0.2304],\n",
       "        [-0.4820,  0.3996],\n",
       "        [-0.3113,  0.8246],\n",
       "        [-0.3352,  0.7335],\n",
       "        [-0.5589,  0.8252],\n",
       "        [-0.4166,  0.7657],\n",
       "        [-0.3923,  0.7849],\n",
       "        [-0.1242,  0.5473]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: simple matrix\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) --> (B, T, C)\n",
    "xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "718b3885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6474,  0.2304],\n",
       "        [-0.4820,  0.3996],\n",
       "        [-0.3113,  0.8246],\n",
       "        [-0.3352,  0.7335],\n",
       "        [-0.5589,  0.8252],\n",
       "        [-0.4166,  0.7657],\n",
       "        [-0.3923,  0.7849],\n",
       "        [-0.1242,  0.5473]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "xbow3 = wei @ x\n",
    "xbow3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f3618a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention\n",
    "torch.manual_seed(13337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "\n",
    "# single head self attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, T) --> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "v = value(x) # (B, T, head_size)\n",
    "out = wei @ v # (B, T, T) @ (B, T, head_size) --> (B, T, head_size)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "996cd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled attention\n",
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size **-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5533dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9380)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0ff87b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9671)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f886c712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0558)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "deb00d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "09ddf218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * 8, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b9e4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if all methods equal\n",
    "print(torch.allclose(xbow, xbow2))\n",
    "print(torch.allclose(xbow2, xbow3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fb72f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / a.sum(1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"--\")\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"--\")\n",
    "print(\"c=\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7987e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
